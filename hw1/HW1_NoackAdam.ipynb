{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR10('../data/CIFAR-10', train=True, download=True,\n",
    "         transform=train_transform), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR10('../data/CIFAR-10', train=False, download=True,\n",
    "         transform=test_transform),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "#### Implement KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, train_loader):\n",
    "        self.train_x, self.train_y = [],[]\n",
    "        for i in range(len(train_loader.dataset)):\n",
    "            x, y = train_loader.dataset[i]\n",
    "            self.train_x.append(x.reshape(1, -1))\n",
    "            self.train_y.append(torch.Tensor([[y]]))\n",
    "        self.train_x = torch.cat(self.train_x, dim=0).to(device)\n",
    "        self.train_y = torch.cat(self.train_y, dim=0).to(device)\n",
    "        \n",
    "    def predict(self, test_x, k=2, p=1):\n",
    "        test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "        dists = torch.cdist(test_x, self.train_x, p)\n",
    "        idxs = torch.topk(dists, k=k, dim=1, largest=False)[1]\n",
    "        test_y_s = self.train_y[idxs]\n",
    "        if k == 1:\n",
    "            test_y_s = test_y_s.squeeze(dim=1)\n",
    "        else:\n",
    "            test_y_s = test_y_s.squeeze(dim=2)\n",
    "        test_y_ = torch.mode(test_y_s, dim=1)[0]\n",
    "        return test_y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for KNN with k = 1, norm = l1: 38.59\n",
      "Test accuracy for KNN with k = 2, norm = l1: 33.92\n",
      "Test accuracy for KNN with k = 3, norm = l1: 36.25\n",
      "Test accuracy for KNN with k = 4, norm = l1: 36.84\n",
      "Test accuracy for KNN with k = 1, norm = l2: 35.39\n",
      "Test accuracy for KNN with k = 2, norm = l2: 31.16\n",
      "Test accuracy for KNN with k = 3, norm = l2: 33.03\n",
      "Test accuracy for KNN with k = 4, norm = l2: 33.98\n"
     ]
    }
   ],
   "source": [
    "for p in [1, 2]:\n",
    "    for k in range(1, 5):\n",
    "        correct = 0\n",
    "        for batch_idx, (samples, labels) in enumerate(test_loader):\n",
    "            samples, labels = samples.to(device), labels.to(device)\n",
    "            preds = knn.predict(samples, k=k, p=p)\n",
    "            correct += torch.sum(torch.eq(preds, labels)).item()\n",
    "        test_acc = correct / len(test_loader.dataset)\n",
    "        print(f'Test accuracy for KNN with k = {k}, norm = l{p}: {test_acc*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "#### Implement simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDNet(nn.Module):\n",
    "    \"\"\"Very simple CIFAR-10 DDNet. Described here: https://arxiv.org/abs/1511.04508.\n",
    "    \"\"\"\n",
    "    def __init__(self, activation=F.relu, p_drop=.5):\n",
    "        super(DDNet, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.logits = None\n",
    "        self.probabilities = None\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(128*5*5, 256)\n",
    "        self.fc1_drop = nn.Dropout(p=p_drop)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc2_drop = nn.Dropout(p=p_drop)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.pool1(self.activation(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = self.pool2(self.activation(self.conv4(x)))\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.fc1_drop(self.fc1(x))\n",
    "        x = self.fc2_drop(self.fc2(x))\n",
    "        self.logits = self.fc3(x)\n",
    "        self.probabilities = F.log_softmax(self.logits, dim=1)\n",
    "        return self.probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function runs both training and test passes through data\n",
    "def datapass(dataloader, train=True):\n",
    "    if train:\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    total_loss = 0\n",
    "    for batch_idx, (samples, labels) in enumerate(dataloader):\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(samples)\n",
    "        \n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        num_correct += torch.eq(preds, labels).sum().item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return num_correct / len(dataloader.dataset), total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_acc, train_loss = datapass(train_loader)\n",
    "        if epoch % print_freq == 0:\n",
    "            print(f'Epoch #{epoch}:\\tTrain loss: {train_loss:.4f}\\tTrain acc: {train_acc:.4f}')\n",
    "        lr_decayer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_epochs = 20\n",
    "lr = .05\n",
    "momentum = .6\n",
    "print_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5:\tTrain loss: 1.0513\tTrain acc: 0.6313\n",
      "Epoch #10:\tTrain loss: 0.5794\tTrain acc: 0.7985\n",
      "Epoch #15:\tTrain loss: 0.2639\tTrain acc: 0.9091\n",
      "Epoch #20:\tTrain loss: 0.1266\tTrain acc: 0.9639\n",
      "With p_drop = 0.125, wd = 0.0001; test accuracy: 0.7502\n",
      "\n",
      "Epoch #5:\tTrain loss: 1.2766\tTrain acc: 0.5474\n",
      "Epoch #10:\tTrain loss: 0.7239\tTrain acc: 0.7480\n",
      "Epoch #15:\tTrain loss: 0.4443\tTrain acc: 0.8471\n",
      "Epoch #20:\tTrain loss: 0.3055\tTrain acc: 0.8992\n",
      "With p_drop = 0.125, wd = 0.001; test accuracy: 0.7617\n",
      "\n",
      "Epoch #5:\tTrain loss: 1.5871\tTrain acc: 0.4255\n",
      "Epoch #10:\tTrain loss: 1.3664\tTrain acc: 0.5101\n",
      "Epoch #15:\tTrain loss: 1.2059\tTrain acc: 0.5733\n",
      "Epoch #20:\tTrain loss: 1.1029\tTrain acc: 0.6125\n",
      "With p_drop = 0.125, wd = 0.01; test accuracy: 0.5909\n",
      "\n",
      "Epoch #5:\tTrain loss: 1.0641\tTrain acc: 0.6264\n",
      "Epoch #10:\tTrain loss: 0.5764\tTrain acc: 0.7999\n",
      "Epoch #15:\tTrain loss: 0.2890\tTrain acc: 0.9008\n",
      "Epoch #20:\tTrain loss: 0.1607\tTrain acc: 0.9505\n",
      "With p_drop = 0.25, wd = 0.0001; test accuracy: 0.7731\n",
      "\n",
      "Epoch #5:\tTrain loss: 1.0779\tTrain acc: 0.6209\n",
      "Epoch #10:\tTrain loss: 0.6248\tTrain acc: 0.7832\n",
      "Epoch #15:\tTrain loss: 0.3489\tTrain acc: 0.8815\n",
      "Epoch #20:\tTrain loss: 0.2109\tTrain acc: 0.9341\n",
      "With p_drop = 0.25, wd = 0.001; test accuracy: 0.7675\n",
      "\n",
      "Epoch #5:\tTrain loss: 2.3028\tTrain acc: 0.0981\n",
      "Epoch #10:\tTrain loss: 2.3028\tTrain acc: 0.0980\n",
      "Epoch #15:\tTrain loss: 2.3027\tTrain acc: 0.0973\n",
      "Epoch #20:\tTrain loss: 2.3026\tTrain acc: 0.1000\n",
      "With p_drop = 0.25, wd = 0.01; test accuracy: 0.1\n",
      "\n",
      "Epoch #5:\tTrain loss: 1.0564\tTrain acc: 0.6298\n",
      "Epoch #10:\tTrain loss: 0.5972\tTrain acc: 0.7921\n",
      "Epoch #15:\tTrain loss: 0.3020\tTrain acc: 0.8938\n",
      "Epoch #20:\tTrain loss: 0.1764\tTrain acc: 0.9404\n",
      "With p_drop = 0.5, wd = 0.0001; test accuracy: 0.7802\n",
      "\n",
      "Epoch #5:\tTrain loss: 1.1722\tTrain acc: 0.5863\n",
      "Epoch #10:\tTrain loss: 0.6914\tTrain acc: 0.7600\n",
      "Epoch #15:\tTrain loss: 0.4280\tTrain acc: 0.8518\n",
      "Epoch #20:\tTrain loss: 0.2988\tTrain acc: 0.9001\n",
      "With p_drop = 0.5, wd = 0.001; test accuracy: 0.7794\n",
      "\n",
      "Epoch #5:\tTrain loss: 1.7149\tTrain acc: 0.3770\n",
      "Epoch #10:\tTrain loss: 1.4869\tTrain acc: 0.4587\n",
      "Epoch #15:\tTrain loss: 1.3231\tTrain acc: 0.5228\n",
      "Epoch #20:\tTrain loss: 1.2264\tTrain acc: 0.5639\n",
      "With p_drop = 0.5, wd = 0.01; test accuracy: 0.5628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p_drop in [.125, .25, .5]:\n",
    "    for wd in [.0001, .001, .01]:\n",
    "        net = DDNet(p_drop=p_drop)\n",
    "        net.cuda()\n",
    "\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
    "        lr_decayer = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0)\n",
    "\n",
    "        train()\n",
    "        test_acc, test_loss = datapass(test_loader, train=False)\n",
    "        print(f'With p_drop = {p_drop}, wd = {wd}; test accuracy: {test_acc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "#### Simple linear classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best values from the grid search in part 2\n",
    "wd = .0001\n",
    "p_drop = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinNet1(nn.Module):\n",
    "    def __init__(self, bias=True):\n",
    "        super(LinNet1, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 10, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "class LinNet2(nn.Module):\n",
    "    def __init__(self, nh1, nh2):\n",
    "        super(LinNet2, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, nh1)\n",
    "        self.fc2 = nn.Linear(nh1, nh2)\n",
    "        self.fc3 = nn.Linear(nh2, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train simple linear classifier WITH bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5:\tTrain loss: 4.0884\tTrain acc: 0.2853\n",
      "Epoch #10:\tTrain loss: 1.9403\tTrain acc: 0.3684\n",
      "Epoch #15:\tTrain loss: 1.6660\tTrain acc: 0.4305\n",
      "Epoch #20:\tTrain loss: 1.6242\tTrain acc: 0.4519\n",
      "Test accuracy: 0.4131\n"
     ]
    }
   ],
   "source": [
    "net = LinNet1(bias=True)\n",
    "net.cuda()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
    "lr_decayer = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0)\n",
    "\n",
    "train()\n",
    "test_acc, test_loss = datapass(test_loader, train=False)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train simple linear classifier WITHOUT bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5:\tTrain loss: 4.4575\tTrain acc: 0.2773\n",
      "Epoch #10:\tTrain loss: 1.9700\tTrain acc: 0.3642\n",
      "Epoch #15:\tTrain loss: 1.6784\tTrain acc: 0.4245\n",
      "Epoch #20:\tTrain loss: 1.6376\tTrain acc: 0.4471\n",
      "Test accuracy: 0.4041\n"
     ]
    }
   ],
   "source": [
    "net = LinNet1(bias=False)\n",
    "net.cuda()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
    "lr_decayer = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0)\n",
    "\n",
    "train()\n",
    "test_acc, test_loss = datapass(test_loader, train=False)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train neural net with 2 hidden layers but no nonlinear activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5:\tTrain loss: 1.7597\tTrain acc: 0.3886\n",
      "Epoch #10:\tTrain loss: 1.7160\tTrain acc: 0.4099\n",
      "Epoch #15:\tTrain loss: 1.6812\tTrain acc: 0.4267\n",
      "Epoch #20:\tTrain loss: 1.6642\tTrain acc: 0.4348\n",
      "Test accuracy: 0.4116\n"
     ]
    }
   ],
   "source": [
    "net = LinNet2(50, 50)\n",
    "net.cuda()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
    "lr_decayer = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0)\n",
    "\n",
    "train()\n",
    "test_acc, test_loss = datapass(test_loader, train=False)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
